{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Chatbot application with Chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001286C2550F0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001286C255D80>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat message history, chat history and Runnable Base chat history\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\",groq_api_key=groq_api_key)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Ashwin, it's nice to meet you! What can I do for you today? 😊\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 15, 'total_tokens': 39, 'completion_time': 0.043636364, 'prompt_time': 7.5489e-05, 'queue_time': 0.013625981, 'total_time': 0.043711853}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-31474025-e355-4512-a7f2-ad473e44e357-0', usage_metadata={'input_tokens': 15, 'output_tokens': 24, 'total_tokens': 39})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "llm.invoke([HumanMessage(content=\"Hi my name is Ashwin\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Ashwin.  You told me so just now!  😊  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 52, 'total_tokens': 72, 'completion_time': 0.036363636, 'prompt_time': 0.002198721, 'queue_time': 0.012333367000000001, 'total_time': 0.038562357}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9d47553a-f7fe-4efd-b560-8b7a3c4255d6-0', usage_metadata={'input_tokens': 52, 'output_tokens': 20, 'total_tokens': 72})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi my name is Ashwin\"),\n",
    "        AIMessage(content=\"Hi Ashwin, it's nice to meet you! What can I do for you today? 😊\\n\"),\n",
    "        HumanMessage(content=\"What is My name?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChatHistory is used to store history in a db so it is statefull\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "data_store = {}\n",
    "\n",
    "def get_chat_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in data_store:\n",
    "        data_store[session_id] = ChatMessageHistory()\n",
    "    return data_store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_chat_memory_model = RunnableWithMessageHistory(llm,get_chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to learn it!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 14, 'total_tokens': 52, 'completion_time': 0.069090909, 'prompt_time': 7.5589e-05, 'queue_time': 0.013242969, 'total_time': 0.069166498}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8764e745-5639-4e9a-9785-3c15dd595e10-0', usage_metadata={'input_tokens': 14, 'output_tokens': 38, 'total_tokens': 52})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_chat_memory_model.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's nice to meet you, Ashwin! 👋  Is there anything I can help you with today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 65, 'total_tokens': 91, 'completion_time': 0.047272727, 'prompt_time': 0.001838362, 'queue_time': 0.011790358, 'total_time': 0.049111089}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3f9bee1c-0380-4680-8625-0b72f8fddcdf-0', usage_metadata={'input_tokens': 65, 'output_tokens': 26, 'total_tokens': 91})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_chat_memory_model.invoke(\n",
    "    [HumanMessage(content=\"My name is Ashwin\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Ashwin.  \\n\\nI remember our previous conversation! 😊  Is there anything else you'd like to talk about? \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 104, 'total_tokens': 136, 'completion_time': 0.058181818, 'prompt_time': 0.003653015, 'queue_time': 0.009847334999999999, 'total_time': 0.061834833}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-64f6ebfc-451a-4716-82f4-4a222c2b7e2f-0', usage_metadata={'input_tokens': 104, 'output_tokens': 32, 'total_tokens': 136})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_chat_memory_model.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to learn it!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 14, 'total_tokens': 52, 'completion_time': 0.069090909, 'prompt_time': 7.5589e-05, 'queue_time': 0.013242969, 'total_time': 0.069166498}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8764e745-5639-4e9a-9785-3c15dd595e10-0', usage_metadata={'input_tokens': 14, 'output_tokens': 38, 'total_tokens': 52}), HumanMessage(content='My name is Ashwin', additional_kwargs={}, response_metadata={}), AIMessage(content=\"It's nice to meet you, Ashwin! 👋  Is there anything I can help you with today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 65, 'total_tokens': 91, 'completion_time': 0.047272727, 'prompt_time': 0.001838362, 'queue_time': 0.011790358, 'total_time': 0.049111089}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3f9bee1c-0380-4680-8625-0b72f8fddcdf-0', usage_metadata={'input_tokens': 65, 'output_tokens': 26, 'total_tokens': 91}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Your name is Ashwin.  \\n\\nI remember our previous conversation! 😊  Is there anything else you'd like to talk about? \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 104, 'total_tokens': 136, 'completion_time': 0.058181818, 'prompt_time': 0.003653015, 'queue_time': 0.009847334999999999, 'total_time': 0.061834833}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-64f6ebfc-451a-4716-82f4-4a222c2b7e2f-0', usage_metadata={'input_tokens': 104, 'output_tokens': 32, 'total_tokens': 136})])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Using Chat Prompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer all queries!\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Ashwin, it's nice to meet you!\\n\\nI'm ready to assist you with any questions or tasks you may have.  Just ask away! 😊  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 24, 'total_tokens': 64, 'completion_time': 0.072727273, 'prompt_time': 0.00013502, 'queue_time': 0.01405522, 'total_time': 0.072862293}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6e31f9c3-5822-4d98-bc5c-11a30ba772a1-0', usage_metadata={'input_tokens': 24, 'output_tokens': 40, 'total_tokens': 64})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(\"My name is Ashwin\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a helpful assistant, I have no access to your personal information, including your name.  If you'd like to tell me your name, I'd be happy to know! 😊  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 24, 'total_tokens': 68, 'completion_time': 0.08, 'prompt_time': 0.001625643, 'queue_time': 0.013157385, 'total_time': 0.081625643}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0433652c-da86-461f-97a6-d1d1484f5e26-0', usage_metadata={'input_tokens': 24, 'output_tokens': 44, 'total_tokens': 68})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_chat_memory_model = RunnableWithMessageHistory(chain,get_chat_history)\n",
    "config = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "with_chat_memory_model.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You need to translate the sentence to {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain=prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ഞാൻ അശ്വിൻ ആണ് (njan ashwin aanu) \\n\\n\\nLet me break it down:\\n\\n* **ഞാൻ (njan)** - I\\n* **അശ്വിൻ (ashwin)** - Ashwin\\n* **ആണ് (aanu)** - am \\n\\n\\nThis translates directly to \"I am Ashwin\".  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 23, 'total_tokens': 101, 'completion_time': 0.141818182, 'prompt_time': 0.00017511, 'queue_time': 0.013379150000000001, 'total_time': 0.141993292}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2070d7ad-03f7-4aac-9b46-1fd137d51b1e-0', usage_metadata={'input_tokens': 23, 'output_tokens': 78, 'total_tokens': 101})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"My name is Ashwin\")],\"language\":\"malayalam\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_chat_memory_model=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_chat_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The Malayalam translation of \"What is my name?\" is:\\n\\n**എന്റെ പേരെന്താണ്?** (ente pe reanthaan?) \\n\\n\\nLet me know if you have any other sentences you\\'d like me to translate!\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 23, 'total_tokens': 77, 'completion_time': 0.098181818, 'prompt_time': 0.000309109, 'queue_time': 0.01368326, 'total_time': 0.098490927}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd63d154-6b08-428e-8d97-db273b38601f-0', usage_metadata={'input_tokens': 23, 'output_tokens': 54, 'total_tokens': 77})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "with_chat_memory_model.invoke({\n",
    "    'messages':[HumanMessage(content=\"What is my name?\")],'language':'malayalam'},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One important concept to understand when building chatbots is how to manage conversation history.\n",
    "#So needed a system to trim the message\n",
    "#trim_message helps us with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages,HumanMessage,AIMessage\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=40,\n",
    "    strategy='last',\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages= [\n",
    "        HumanMessage(content=\"Hi my name is Ashwin\"),\n",
    "        AIMessage(content=\"Hi Ashwin, it's nice to meet you! What can I do for you today? 😊\\n\"),\n",
    "        HumanMessage(content=\"I love Football\"),\n",
    "        AIMessage(content=\"Oh Nice! 😊\\n\"),\n",
    "        HumanMessage(content=\"I like Icream, chocolate flavour\"),\n",
    "        AIMessage(content=\"Oh Nice! 😊\\n\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashwi\\OneDrive\\Desktop\\AI\\langchain\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\ashwi\\OneDrive\\Desktop\\AI\\langchain\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ashwi\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='I love Football', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Oh Nice! 😊\\n', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like Icream, chocolate flavour', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Oh Nice! 😊\\n', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You said you like ice cream!   🍦  So yes, you like ice cream. \\n\\nWhat's your favorite flavor? 😋\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"Do I like icecream?\")],\n",
    "        \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
